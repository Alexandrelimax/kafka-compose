{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90de797a",
   "metadata": {},
   "source": [
    "# Tutorial: Kafka com Python usando confluent-kafka\n",
    "\n",
    "Este notebook mostra como configurar um Producer e um Consumer para Apache Kafka usando a biblioteca `confluent-kafka`.\n",
    "\n",
    "## Pré-requisitos\n",
    "1. **Kafka e ZooKeeper**: Configure o Kafka usando Docker Compose.\n",
    "2. **Bibliotecas Python**: Certifique-se de instalar os pacotes necessários:\n",
    "   ```bash\n",
    "   pip install confluent-kafka python-dotenv\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3aef19",
   "metadata": {},
   "source": [
    "## 1. Configuração do Docker Compose para Kafka e ZooKeeper\n",
    "\n",
    "Crie um arquivo `docker-compose.yml` com o seguinte conteúdo para configurar Kafka e ZooKeeper:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  zookeeper:\n",
    "    image: bitnami/zookeeper:3.8.0\n",
    "    container_name: zookeeper\n",
    "    environment:\n",
    "      - ALLOW_ANONYMOUS_LOGIN=yes\n",
    "    ports:\n",
    "      - \"2181:2181\"\n",
    "    networks:\n",
    "      - kafka_network\n",
    "\n",
    "  kafka-1:\n",
    "    image: bitnami/kafka:3.5.2\n",
    "    container_name: kafka-1\n",
    "    environment:\n",
    "      - KAFKA_CFG_BROKER_ID=1\n",
    "      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181\n",
    "      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,INTERNAL://:29092\n",
    "      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://${KAFKA_ADVERTISED_LISTENER_IP}:9092,INTERNAL://kafka-1:29092\n",
    "      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT\n",
    "      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=2\n",
    "      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=2\n",
    "      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "    ports:\n",
    "      - \"9092:9092\"\n",
    "      - \"29092:29092\"\n",
    "    networks:\n",
    "      - kafka_network\n",
    "\n",
    "  kafka-2:\n",
    "    image: bitnami/kafka:3.5.2\n",
    "    container_name: kafka-2\n",
    "    environment:\n",
    "      - KAFKA_CFG_BROKER_ID=2\n",
    "      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181\n",
    "      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9093,INTERNAL://:29093\n",
    "      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://${KAFKA_ADVERTISED_LISTENER_IP}:9093,INTERNAL://kafka-2:29093\n",
    "      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT\n",
    "      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=2\n",
    "      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=2\n",
    "      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "    ports:\n",
    "      - \"9093:9093\"\n",
    "      - \"29093:29093\"\n",
    "    networks:\n",
    "      - kafka_network\n",
    "\n",
    "  kafka-3:\n",
    "    image: bitnami/kafka:3.5.2\n",
    "    container_name: kafka-3\n",
    "    environment:\n",
    "      - KAFKA_CFG_BROKER_ID=3\n",
    "      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181\n",
    "      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9094,INTERNAL://:29094\n",
    "      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://${KAFKA_ADVERTISED_LISTENER_IP}:9094,INTERNAL://kafka-3:29094\n",
    "      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT\n",
    "      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=2\n",
    "      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=2\n",
    "      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "    ports:\n",
    "      - \"9094:9094\"\n",
    "      - \"29094:29094\"\n",
    "    networks:\n",
    "      - kafka_network\n",
    "\n",
    "networks:\n",
    "  kafka_network:\n",
    "    name: kafka_network\n",
    "    driver: bridge\n",
    "```\n",
    "\n",
    "Execute o seguinte comando para iniciar os serviços:\n",
    "\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "Certifique-se de que os contêineres Kafka e ZooKeeper estão em execução."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f88d1",
   "metadata": {},
   "source": [
    "## 2. Instalando a Biblioteca `confluent-kafka`\n",
    "\n",
    "Antes de configurar o **Producer**, é necessário instalar a biblioteca Python `confluent-kafka`. Esta biblioteca é uma interface cliente baseada em **librdkafka**, que permite interagir de forma eficiente com o Apache Kafka.\n",
    "\n",
    "#### Passo 1: Instalar a Biblioteca\n",
    "Execute o comando abaixo no terminal para instalar a biblioteca:\n",
    "\n",
    "```bash\n",
    "pip install confluent-kafka\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab219326",
   "metadata": {},
   "source": [
    "## 3. Configurando o Producer (Produtor)\n",
    "\n",
    "O Producer envia mensagens para o Kafka. Abaixo está um código exemplo para configurá-lo usando python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"Callback para confirmar o envio da mensagem.\"\"\"\n",
    "    if err:\n",
    "        print(f\"Erro ao enviar mensagem: {err}\")\n",
    "    else:\n",
    "        print(f\"Mensagem enviada para o tópico {msg.topic()} [partição {msg.partition()}] offset {msg.offset()}\")\n",
    "\n",
    "\n",
    "def produce_message():\n",
    "    config = {\n",
    "        'bootstrap.servers': 'localhost:9092',  # Endereço do Kafka\n",
    "    }\n",
    "\n",
    "    producer = Producer(config)\n",
    "\n",
    "    topic = 'test-topic'\n",
    "    message = \"Hello, Kafka from Python!\"\n",
    "\n",
    "    try:\n",
    "        producer.produce(topic, value=message, callback=delivery_report)\n",
    "        producer.flush()  # Garante o envio antes de sair\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao produzir mensagem: {e}\")\n",
    "\n",
    "\n",
    "produce_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732ad94",
   "metadata": {},
   "source": [
    "## 4. Configurando o Consumer (Consumidor)\n",
    "\n",
    "O Consumer lê as mensagens do Kafka. Abaixo está o código para configurá-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException\n",
    "\n",
    "\n",
    "def consume_messages():\n",
    "    config = {\n",
    "        'bootstrap.servers': 'localhost:9092',\n",
    "        'group.id': 'python-consumer-group',  # Grupo de consumidores\n",
    "        'auto.offset.reset': 'earliest',  # Começa do início do tópico\n",
    "    }\n",
    "\n",
    "    consumer = Consumer(config)\n",
    "    topic = 'test-topic'\n",
    "\n",
    "    try:\n",
    "        consumer.subscribe([topic])\n",
    "\n",
    "        print(f\"Consumindo mensagens do tópico: {topic}\")\n",
    "        while True:\n",
    "            msg = consumer.poll(timeout=1.0)  # Espera por mensagens\n",
    "\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaException._PARTITION_EOF:\n",
    "                    print(\"Fim da partição.\")\n",
    "                else:\n",
    "                    print(f\"Erro: {msg.error()}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Recebido: chave = {msg.key()}, valor = {msg.value()}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Encerrando o consumidor.\")\n",
    "    finally:\n",
    "        consumer.close()\n",
    "\n",
    "\n",
    "consume_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32e97f",
   "metadata": {},
   "source": [
    "## 5. Testando o Producer e Consumer\n",
    "\n",
    "1. **Inicie o Producer:**\n",
    "   Execute o código da célula do Producer para enviar mensagens ao Kafka.\n",
    "2. **Inicie o Consumer:**\n",
    "   Execute o código da célula do Consumer para consumir as mensagens enviadas pelo Producer.\n",
    "\n",
    "Certifique-se de que ambos estejam funcionando corretamente. Você verá as mensagens do Producer no terminal do Consumer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb1dd8",
   "metadata": {},
   "source": [
    "## 6. Conclusão\n",
    "\n",
    "Neste tutorial, aprendemos como configurar um ambiente Kafka com Docker Compose e interagir com ele usando Python. Criamos um Producer para enviar mensagens e um Consumer para recebê-las.\n",
    "\n",
    "### Próximos passos:\n",
    "- Explore particionamento de tópicos e grupos de consumidores.\n",
    "- Use ferramentas como Prometheus e Grafana para monitorar o Kafka."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6e99f",
   "metadata": {},
   "source": [
    "### FIM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
